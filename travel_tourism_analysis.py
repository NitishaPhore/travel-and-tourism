# -*- coding: utf-8 -*-
"""travel_tourism_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L7Byz4Qke6MYbQDvnDynAelJpvFS-sOE
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
df=pd.read_csv("/content/final_df.csv")
df.head()

df.drop(columns=['ReviewText',"Gender","Preferences","Email"],inplace=True)

df.head()

df.info()

df.describe()

# quick look
print(df.shape)
print(df.columns.tolist())
display(df.head())

print(df.isnull().sum())
df['VisitDate'] = pd.to_datetime(df['VisitDate'], errors='coerce')

print("VisitDate parse nulls:", df['VisitDate'].isnull().sum())

numeric_cols = ['Rating','Popularity','ExperienceRating','NumberOfAdults','NumberOfChildren']
for c in numeric_cols:
    df[c] = pd.to_numeric(df[c], errors='coerce')


df = df.dropna(axis=0, how='any')
print("After dropna:", df.shape)

print(df[numeric_cols].describe().transpose())
categorical_cols = ['State', 'Type', 'BestTimeToVisit', 'Name_x', 'Name_y']
for c in categorical_cols:
    print(f"\nTop values for {c}:")
    print(df[c].value_counts().head(10))

plt.figure(figsize=(8,4))
plt.hist(df['Rating'], bins=range(int(df['Rating'].min()), int(df['Rating'].max())+2), edgecolor='black')
plt.xlabel('Rating')
plt.ylabel('Count')
plt.title('Distribution of Rating')
plt.grid(axis='y', alpha=0.3)
plt.show()

type_counts = df['Type'].value_counts()
plt.figure(figsize=(8,4))
plt.bar(type_counts.index, type_counts.values)
plt.xlabel('Type')
plt.ylabel('Count')
plt.title('Counts by Type')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

plt.figure(figsize=(10,5))
types = df['Type'].unique()
data_to_plot = [df.loc[df['Type']==t, 'Popularity'].dropna() for t in types]
plt.boxplot(data_to_plot, labels=types, showfliers=False)
plt.ylabel('Popularity')
plt.title('Popularity distribution by Type')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

plt.figure(figsize=(7,5))
plt.scatter(df['Popularity'], df['ExperienceRating'], alpha=0.6)
plt.xlabel('Popularity')
plt.ylabel('ExperienceRating')
plt.title('Popularity vs Experience Rating')
plt.grid(alpha=0.3)
plt.show()

# Ensure VisitDate is datetime
df_time = df.copy()
df_time.set_index('VisitDate', inplace=True)
monthly = df_time.resample('M').size()

plt.figure(figsize=(10,4))
plt.plot(monthly.index, monthly.values, marker='o', linewidth=1)
plt.xlabel('Month')
plt.ylabel('Number of Visits')
plt.title('Visits per Month')
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

corr_cols = ['Rating','Popularity','ExperienceRating','NumberOfAdults','NumberOfChildren']
corr = df[corr_cols].corr()

plt.figure(figsize=(6,5))
im = plt.imshow(corr, vmin=-1, vmax=1)
plt.colorbar(im, fraction=0.046, pad=0.04)
plt.xticks(range(len(corr_cols)), corr_cols, rotation=45, ha='right')
plt.yticks(range(len(corr_cols)), corr_cols)
plt.title('Correlation matrix')
# Annotate values
for i in range(len(corr_cols)):
    for j in range(len(corr_cols)):
        plt.text(j, i, f"{corr.iloc[i,j]:.2f}", ha='center', va='center', color='white' if abs(corr.iloc[i,j])>0.5 else 'black')
plt.tight_layout()
plt.show()

cat_to_encode = ['State', 'Type', 'BestTimeToVisit']
df_encoded = pd.get_dummies(df, columns=cat_to_encode, drop_first=False)  # drop_first=True avoids dummy trap if needed
print("New shape after one-hot:", df_encoded.shape)

top_names = df['Name_x'].value_counts().nlargest(10).index
df['Name_x_top10'] = df['Name_x'].where(df['Name_x'].isin(top_names), other='Other')
df = pd.get_dummies(df, columns=['Name_x_top10'], prefix='Name', drop_first=False)

from sklearn.preprocessing import StandardScaler, MinMaxScaler

num_cols = ['Rating','Popularity','ExperienceRating','NumberOfAdults','NumberOfChildren']

scaler_std = StandardScaler()
df_encoded_std = df_encoded.copy()
df_encoded_std[num_cols] = scaler_std.fit_transform(df_encoded_std[num_cols])
print("Standard scaled sample:")
print(df_encoded_std[num_cols].describe().transpose())

scaler_mm = MinMaxScaler()
df_encoded_mm = df_encoded.copy()
df_encoded_mm[num_cols] = scaler_mm.fit_transform(df_encoded_mm[num_cols])
print("MinMax scaled sample (0-1):")
print(df_encoded_mm[num_cols].describe().transpose())

df_encoded_std.to_csv('processed_data_standard_scaled.csv', index=False)

df_encoded_mm.to_csv('processed_data_minmax_scaled.csv', index=False)

df.head()

df.info()

df.drop(columns=["Name_x"],inplace=True)
df.info()

df = pd.get_dummies(df, columns=['Type', 'BestTimeToVisit'], drop_first=False)

df.head()

df['VisitDate'] = pd.to_datetime(df['VisitDate'])

df['Year'] = df['VisitDate'].dt.year
df['Month'] = df['VisitDate'].dt.month
df['Day'] = df['VisitDate'].dt.day
df['DayOfWeek'] = df['VisitDate'].dt.dayofweek

df=df.drop(columns=['VisitDate'])

df.head()

df.info()

# 1. NUMERIC COLUMNS LIST
numeric_cols = [
    'Rating', 'Popularity', 'ExperienceRating',
    'NumberOfAdults', 'NumberOfChildren'
]

date_numeric = ['Year','Month','Day','DayOfWeek']

# 2. PLOT DISTRIBUTIONS (Histograms)

plt.figure(figsize=(12, 8))

for i, col in enumerate(numeric_cols):
    plt.subplot(2, 3, i+1)
    plt.hist(df[col], bins=10, edgecolor='black')
    plt.title(f'{col} Distribution')
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.grid(alpha=0.3)

plt.tight_layout()
plt.show()

# 3. DATE-RELATED DISTRIBUTIONS

plt.figure(figsize=(12, 8))

for i, col in enumerate(date_numeric):
    plt.subplot(2, 2, i+1)
    plt.hist(df[col], bins=10, edgecolor='black')
    plt.title(f'{col} Distribution')
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.grid(alpha=0.3)

plt.tight_layout()
plt.show()

# 4. SCATTER PLOTS (Simple Relationships)

plt.figure(figsize=(12, 8))

plt.subplot(2, 2, 1)
plt.scatter(df['Popularity'], df['ExperienceRating'], alpha=0.5)
plt.title('Popularity vs ExperienceRating')
plt.xlabel('Popularity')
plt.ylabel('ExperienceRating')

plt.subplot(2, 2, 2)
plt.scatter(df['Rating'], df['ExperienceRating'], alpha=0.5)
plt.title('Rating vs ExperienceRating')
plt.xlabel('Rating')
plt.ylabel('ExperienceRating')

plt.subplot(2, 2, 3)
plt.scatter(df['Popularity'], df['Rating'], alpha=0.5)
plt.title('Popularity vs Rating')
plt.xlabel('Popularity')
plt.ylabel('Rating')

plt.subplot(2, 2, 4)
plt.scatter(df['NumberOfAdults'], df['ExperienceRating'], alpha=0.5)
plt.title('Adults vs ExperienceRating')
plt.xlabel('Adults')
plt.ylabel('ExperienceRating')

plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 6))

# Type Feature Count
plt.subplot(1, 2, 1)
type_cols = [c for c in df.columns if c.startswith("Type_")]
df[type_cols].sum().plot(kind='bar')
plt.title("Type Counts")
plt.xticks(rotation=45)

# Best Time to Visit Count
plt.subplot(1, 2, 2)
bt_cols = [c for c in df.columns if c.startswith("BestTimeToVisit_")]
df[bt_cols].sum().plot(kind='bar')
plt.title("Best Time to Visit Counts")
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

df_raw=pd.read_csv("/content/final_df.csv")

df=df.drop(columns=['Name_Goa Beaches',"Name_Jaipur City",'Name_Kerala Backwaters','Name_Leh Ladakh','Name_Taj Mahal'])

df = pd.concat([df, df_raw["Name_x"]], axis=1)
df.head()

df.info()

y = df["Name_x"]
# X = df.drop(["Name_x", "ReviewID", "DestinationID_x", "DestinationID_y", "UserID", "HistoryID"], axis=1)
X = df.drop(["Name_x"], axis=1)

X = X.astype(int)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

from sklearn.preprocessing import StandardScaler

scaler_std = StandardScaler()
X_train_std = scaler_std.fit_transform(X_train)
X_test_std = scaler_std.transform(X_test)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train_std, y_train)

y_pred = knn.predict(X_test_std)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

sample_input = {
    "ReviewID": 2001,
    "DestinationID_x": 5,
    "UserID": 122,
    "Rating": 4,
    "Popularity": 82.3,
    "HistoryID": 55,
    "DestinationID_y": 5,
    "ExperienceRating": 5,
    "NumberOfAdults": 2,
    "NumberOfChildren": 1,
    "Type_Adventure": 0,
    "Type_Beach": 1,
    "Type_City": 0,
    "Type_Historical": 0,
    "Type_Nature": 0,
    "BestTimeToVisit_Apr-Jun": 0,
    "BestTimeToVisit_Nov-Feb": 0,
    "BestTimeToVisit_Nov-Mar": 0,
    "BestTimeToVisit_Oct-Mar": 1,
    "BestTimeToVisit_Sep-Mar": 0,
    "Year": 2024,
    "Month": 1,
    "Day": 15,
    "DayOfWeek": 0
}
X_new = pd.DataFrame([sample_input])
X_new_scaled = scaler_std.transform(X_new)
knn.predict(X_new_scaled)

sample_input = {
    "ReviewID": 2002,
    "DestinationID_x": 5,
    "UserID": 124,
    "Rating": 4,
    "Popularity": 90,
    "HistoryID": 55,
    "DestinationID_y": 5,
    "ExperienceRating": 5,
    "NumberOfAdults": 2,
    "NumberOfChildren": 1,
    "Type_Adventure": 0,
    "Type_Beach": 0,
    "Type_City": 0,
    "Type_Historical": 0,
    "Type_Nature": 1,
    "BestTimeToVisit_Apr-Jun": 0,
    "BestTimeToVisit_Nov-Feb": 1,
    "BestTimeToVisit_Nov-Mar": 0,
    "BestTimeToVisit_Oct-Mar": 0,
    "BestTimeToVisit_Sep-Mar": 0,
    "Year": 2024,
    "Month": 1,
    "Day": 15,
    "DayOfWeek": 0
}
X_new = pd.DataFrame([sample_input])
X_new_scaled = scaler_std.transform(X_new)
knn.predict(X_new_scaled)

